{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import torch\n",
    "from torchreid.utils import FeatureExtractor\n",
    "import utils\n",
    "import argparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: pcb_p4\n",
      "- params: 23,508,032\n",
      "- flops: 4,053,270,528\n",
      "Successfully loaded pretrained weights from \"models/model.pth.tar\"\n",
      "** The following layers are discarded due to unmatched keys or layer size: ['classifier.0.weight', 'classifier.0.bias', 'classifier.1.weight', 'classifier.1.bias', 'classifier.2.weight', 'classifier.2.bias', 'classifier.3.weight', 'classifier.3.bias']\n"
     ]
    }
   ],
   "source": [
    "video_name = \"p4_1\"\n",
    "\n",
    "backbone = 'pcb_p4'\n",
    "model_path = \"models/model.pth.tar\".format(backbone)\n",
    "\n",
    "device = 'cpu'\n",
    "if torch.cuda.is_available():\n",
    "    device = 'cuda'\n",
    "extractor = FeatureExtractor(\n",
    "    model_name=backbone,\n",
    "    model_path=model_path,\n",
    "    device=device\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.dnn_DetectionModel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: pcb_p4\n",
      "- params: 23,508,032\n",
      "- flops: 4,053,270,528\n",
      "Successfully loaded pretrained weights from \"models/model.pth.tar\"\n",
      "** The following layers are discarded due to unmatched keys or layer size: ['classifier.0.weight', 'classifier.0.bias', 'classifier.1.weight', 'classifier.1.bias', 'classifier.2.weight', 'classifier.2.bias', 'classifier.3.weight', 'classifier.3.bias']\n",
      "Webcam selected!\n",
      "Video [p4_1] selected!\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "conf_th = 0.6\n",
    "nms_th = 0.1\n",
    "factor_model=2\n",
    "net = cv2.dnn.readNet(\"models/pallet_block.weights\", \"models/pallet_block.cfg\")\n",
    "net.setPreferableBackend(cv2.dnn.DNN_BACKEND_OPENCV)\n",
    "net.setPreferableTarget(cv2.dnn.DNN_TARGET_CPU)\n",
    "model = cv2.dnn_DetectionModel(net)\n",
    "model.setInputParams(size=(factor_model*128, factor_model*128), scale=1/255, swapRB=True, crop=False)\n",
    "resize_fac=0.5\n",
    "cam_width=1936\n",
    "cam_height=1216\n",
    "center_frame = (int(resize_fac*cam_width/2), int(resize_fac*cam_height/2))\n",
    "max_dist_left=80\n",
    "pallet = []\n",
    "\n",
    "capw = cv2.VideoCapture(0)\n",
    "print(\"Webcam selected!\")\n",
    "print(\"Video [{}] selected!\".format(video_name))\n",
    "cap = cv2.VideoCapture('pallet_videos/' + video_name + '.avi')\n",
    "\n",
    "next_pallet_block=True\n",
    "pallet_block_idx=0\n",
    "signature_img_size = (128, 384)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "ret, frame = cap.read()\n",
    "retw, framew = capw.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "uint8\n",
      "uint8\n"
     ]
    }
   ],
   "source": [
    "print(frame.dtype)\n",
    "print(framew.dtype)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "25816a85d842e1f6535921744cc2a892e6fb95bb3eb21ef96c7ab901cd0ae416"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
